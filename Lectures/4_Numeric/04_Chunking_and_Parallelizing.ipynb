{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Chunking and Parallelizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "__Chunking__ is useful for whenever a task can be accomplished one piece of data at a time. Even some applications that may look like they can't be done using chunking can be done if you think about the problem in the right way!\n",
    "\n",
    "Obvious example: __how would we do a summation using chunking?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "By feeding the `read_csv` function the `chunksize` argument, it becomes an iterable reader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "chonk = pd.read_csv(\"./ex_big.csv\",chunksize=10000)\n",
    "\n",
    "chonk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we wanted to count the number of 1s, for example, we could do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "s = 0\n",
    "for i in chonk:\n",
    "    s += i[\"0\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can also do subsetting this way. Suppose that I wanted to select only cows that are breed \"AY.\" What I'll do is first write an empty dataframe with the column names, then cycle through the columns and writing out only the rows I want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "file_dir=\"C:/Users/jhtchns2/Box/ACE 592 SAE - Spring 2023/Class_Examples/3_Numeric/\"\n",
    "\n",
    "# Read in one row, take the columns\n",
    "cols = pd.read_csv(file_dir+\"naab_example.csv\",nrows=1).columns\n",
    "\n",
    "# Write out an empty dataframe with just the column names\n",
    "pd.DataFrame(columns=cols).to_csv(\"./out.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Get that chonker running.\n",
    "chonker = pd.read_csv(file_dir+\"naab_example.csv\",chunksize=10000)\n",
    "\n",
    "for i in chonker:\n",
    "    i[i['breed']==\"AY\"].to_csv(\"./out.csv\", mode='a', header=False)\n",
    "    \n",
    "pd.read_csv(\"out.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "And nothing had to be run in memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "trade_files = glob.glob(\"P:trade_data/BACI_HS12_V202201/BACI_HS12_Y*.csv\")\n",
    "\n",
    "for F in trade_files:\n",
    "    chonker = pd.read_csv(F,chunksize=100000)\n",
    "    \n",
    "    # Read in one row, take the columns\n",
    "    cols = pd.read_csv(F,nrows=1).columns\n",
    "\n",
    "    # Write out an empty dataframe with just the column names\n",
    "    pd.DataFrame(columns=cols).to_csv(F.split(\".csv\")[0]+\"_m.csv\",index=False)\n",
    "    \n",
    "    for i in chonker:\n",
    "        i['v'] = pd.to_numeric(i['v'],errors=\"coerce\")\n",
    "        i['q'] = pd.to_numeric(i['q'],errors=\"coerce\")\n",
    "        i.to_csv(F.split(\".csv\")[0]+\"_m.csv\", mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for F in trade_files:\n",
    "    os.replace(F.split(\".csv\")[0]+\"_m.csv\",F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#### One example of chunking that I needed to do for the homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now how might we do chunking to calculate the mean and variance of these two arrays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sample = np.random.normal(loc=[4., 20.], scale=[1., 3.5],\n",
    "                           size=(100000000, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "__Try it!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Threading and Parallelization\n",
    "\n",
    "Within one CPU, you can create multiple __threads__ to do tasks concurrently. Across all CPUs, you can create multiple __processes__ to do tasks in parallel.\n",
    "\n",
    "We will mostly be talking about __parallelization__ for computations, but threading is more applicable for less CPU intensive tasks.\n",
    "\n",
    "To parallelize code means to allow your computer cores to run independently but in parallel. This can be helpful when your task needs to be repeated for a list of inputs and collected at the end. __Programs can be parallelized only if each run can be done independently of the other__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Parallel operations:\n",
    "- Bootstrapping a statistic.\n",
    "- Scraping a list of webpages.\n",
    "- Grid search.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Non-parallel operations:\n",
    "- Evaluations of an optimization routine.\n",
    "- Rolling statistics.\n",
    "- The traveling salesman problem.\n",
    "\n",
    "__Why?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Types of parallelization\n",
    "- Synchronous: locks the main program until all processes are finished and returns it in the order it was given.\n",
    "    - Example: in a program where two cores need to square four numbers, the program stops until the cores finish all the numbers. They return the list in the order that they were given.\n",
    "- Asynchronous: does not lock the main program and returns it in the order it finishes.\n",
    "    - Example: in that same program, the program will not stop but the number return in the order that they were finished squaring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import multiprocess as mp\n",
    "\n",
    "def square(x):\n",
    "    return x*x\n",
    "\n",
    "import numpy as np\n",
    "X = np.arange(1,2000000,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Non-parallelized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "[x*x for x in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from multiprocess.pool import ThreadPool\n",
    "\n",
    "thread_pool = ThreadPool(5)\n",
    "res_thread = thread_pool.map(square,X)\n",
    "thread_pool.close()\n",
    "thread_pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "res_thread[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Synchronous Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pool = mp.Pool(5)\n",
    "res_synchr = pool.map(square,X)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "res_synchr[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Asynchronous Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pool = mp.Pool(5)\n",
    "res_async = pool.map_async(square,X)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "res_async.get()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "It is good practice to call `pool.close()` and `pool.join()` in order to close out the processes when you are done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### What took the least amount of time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Threading was the fastest. Why?\n",
    "\n",
    "- It didn't have to create processes, which needs a new python interpreter each time.\n",
    "- The major bottleneck was getting data, not the computation.\n",
    "\n",
    "Another advantage is that it could write to a common array `L`...\n",
    "\n",
    "This leads to a general principle with threading versus parallel:\n",
    "- If I/O bound problem, use threading.\n",
    "    - I/O bound means the most time-consuming part is reading or writing data.\n",
    "- If CPU bound problem, use parallel.\n",
    "    - CPU bound means the most time-consuming part is processing the data.\n",
    "    \n",
    "Squaring a number is not CPU intensive, and setting up new processes is expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A basic bootstrap using `multiprocessing`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sample = np.random.normal(loc=[4., 20.], scale=[20., 40.5],\n",
    "                           size=(10000000, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "ixs = np.random.randint(len(sample),size=len(sample))\n",
    "sample[ixs,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def bootstrap(i):\n",
    "    import numpy as np\n",
    "    ixs = np.random.randint(len(sample),size=len(sample))\n",
    "    df = sample[ixs,:]\n",
    "    return df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pool = mp.Pool(4)\n",
    "res_synchr = pool.map(bootstrap,range(50))\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What happened here?\n",
    "\n",
    "Unfortunately, the new process it creates does not have any of the things in memory it had before. This demonstrates the difference between __threads__ and __processes__:\n",
    "\n",
    "- Threads use the same memory space on 1 CPU and are a __subset of a process__:\n",
    "    - Good if you want threads to share data.\n",
    "    - Bad if those objects are being modified at the same time, because each thread will __lock__ it until its done.\n",
    "- Processes carve out their own memory space to use on multiple CPUs. They are the __superset of threads__:\n",
    "    - Good if computation heavy and needs to edit each object.\n",
    "    - Bad if the operation is simple, because it takes up a lot of memory.\n",
    "\n",
    "Threading is best for lightweight but long activities. Processes are better for computation heavy things that need their own carved out memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Using threads, we can edit a common object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "L = []\n",
    "def square_append(x):\n",
    "    L.append(x*x)\n",
    "    return x*x\n",
    "\n",
    "thread_pool = ThreadPool(5)\n",
    "res_thread = thread_pool.map(square_append,X)\n",
    "thread_pool.close()\n",
    "thread_pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "L[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So we can use bootstrapping with threads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "thread_pool = ThreadPool(5)\n",
    "res_thread = thread_pool.map(bootstrap,range(50))\n",
    "thread_pool.close()\n",
    "thread_pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "np.concatenate(res_thread).reshape(50,2).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we want to use parallel processing, we need to edit the function a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(sample).to_csv(\"sample.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def bootstrap_read(i):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    ixs = np.random.randint(10000000,size=10000000)\n",
    "    df = pd.read_csv(\"sample.csv\").iloc[ixs,:]\n",
    "    return df.mean(axis=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pool = mp.Pool(4)\n",
    "res_synchr = pool.map(bootstrap_read,range(50))\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "Res = np.concatenate(res_synchr)\n",
    "\n",
    "Res.reshape(50,2).mean(axis=0),\\\n",
    "Res.reshape(50,2).std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Lets benchmark against the sequential way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def thread_bootstrap(reps,no_threads=4):\n",
    "    pool = ThreadPool(no_threads)\n",
    "    res_synchr = pool.map(bootstrap,range(reps))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    res = np.concatenate(res_synchr).reshape(reps,2)\n",
    "    return res.mean(axis=0),res.std(axis=0)\n",
    "\n",
    "def parallel_bootstrap(reps,no_workers=4):\n",
    "    pool = mp.Pool(no_workers)\n",
    "    res_synchr = pool.map_async(bootstrap_read,range(reps))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    res = np.concatenate(res_synchr.get()).reshape(reps,2)\n",
    "    return res.mean(axis=0),res.std(axis=0)\n",
    "    \n",
    "def sequential_bootstrap(reps):\n",
    "    res = []\n",
    "    for i in range(reps):\n",
    "        res += [bootstrap(i)]\n",
    "    res = np.concatenate(res).reshape(reps,2)\n",
    "    return res.mean(axis=0),res.std(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "thread_bootstrap(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "parallel_bootstrap(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "sequential_bootstrap(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "thread_bootstrap(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "parallel_bootstrap(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sequential_bootstrap(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's look at how the speed gap changes with B, the number of bootstrap replications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def time_bootstrap(func,B=10):\n",
    "    start = time.time()\n",
    "    \n",
    "    func(B)\n",
    "    \n",
    "    end = time.time()\n",
    "    return end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "seq_boot = [time_bootstrap(sequential_bootstrap,B=x) for x in np.arange(10,2011,100)]\n",
    "thr_boot = [time_bootstrap(thread_bootstrap,B=x) for x in np.arange(10,2011,100)]\n",
    "par_boot = [time_bootstrap(parallel_bootstrap,B=x) for x in np.arange(10,2011,100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "boot_res = pd.DataFrame([seq_boot,thr_boot,par_boot],\\\n",
    "                         index=[\"Sequential\",\"Threading\",\"Parallel\"],\\\n",
    "                         columns = np.arange(10,2011,100)).T\n",
    "\n",
    "boot_res.to_csv(\"bootstrap_bench.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "boot_res = pd.read_csv(\"bootstrap_bench.csv\").set_index(\"Unnamed: 0\")\n",
    "boot_res.plot()\n",
    "plt.xlabel(\"Replications\")\n",
    "plt.ylabel(\"Time in Seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "boot_res = pd.read_csv(\"bootstrap_bench.csv\").set_index(\"Unnamed: 0\")\n",
    "boot_res.iloc[:,:2].plot()\n",
    "plt.xlabel(\"Replications\")\n",
    "plt.ylabel(\"Time in Seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Threading increases in time at a much slower rate than sequential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In this case, parallel was not faster. Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### This is not a CPU bound task, therefore there is no advantage to parallel.\n",
    "\n",
    "It takes far more time to initialize the process than it does to run it (it's a very simple calculation). It takes quite a bit of time to reallocate memory.\n",
    "\n",
    "There is some small overhead to allocate workers, hence why at the lowest value sequential beats parallel.\n",
    "\n",
    "\n",
    "Were the computation to be CPU bound, doing a simple parallel operation in this case would be much better.\n",
    "\n",
    "However, the above seems to be heavily dependent on your computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "There will also be slight speed improvements if there are more workers allocated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "parallel_bootstrap(50,no_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "parallel_bootstrap(50,no_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In general, a good rule of thumb is to have as many workers as you CPUs to use.\n",
    "\n",
    "My computer has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "mp.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can use more than your CPU count provided that they are not tasks that require a lot of memory or CPUs for each one. When you exceed your CPU count you split one cpu into multiple tasks.\n",
    "\n",
    "In this case we are reading in data, which is likely to be very memory intensive. Not in general a good idea to spawn too many of them in this case.\n",
    "\n",
    "__Note:__ If you don't close the pool you are using, you risk creating too many instances and running out of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "parallel_bootstrap(100,no_workers=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Notice that with too many workers you actually lose speed improvments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in range(2,20):\n",
    "    start = time.time()\n",
    "    parallel_bootstrap(500,no_workers=i)\n",
    "    proc_time = time.time() - start\n",
    "    l+= [proc_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(l).to_csv(\"worker_bench.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "l = pd.read_csv(\"worker_bench.csv\")[\"0\"]\n",
    "\n",
    "plt.plot(list(range(2,20)),l,label=\"Parallel\")\n",
    "plt.xlabel(\"Number of Workers\")\n",
    "plt.ylabel(\"Time to do 500 reps\")\n",
    "plt.axvline(8,color='black',ls='--',label=\"Number of Cores\")\n",
    "plt.axhline(24.10096502304077,color=\"C3\",label=\"Sequential\")\n",
    "plt.ylim(5,30)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Depending on the run, more workers does not always equal good performance. In general, always start with allocating 1 core to 1 worker.\n",
    "\n",
    "For most problems, simply setting workers equal to your CPUs is a massive speed improvement."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "rise": {
   "height": "80%",
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
