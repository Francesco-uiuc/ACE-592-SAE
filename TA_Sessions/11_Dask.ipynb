{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18452c52",
   "metadata": {},
   "source": [
    "# Dask DataFrame\n",
    "\n",
    " - Dask is a flexible library for parallel computing using Python.\n",
    " - Besides other powerful tools, we'll focus on Dask DataFrame. \n",
    " - It reuses a lot of pandas code but it extends it to a larger scale. \n",
    " - A Dask DataFrame is a large parallel DataFrame composed of many smaller Pandas DataFrames, split along an index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f55fcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0c61aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url=\"http://dask.pydata.org/en/latest/_images/dask-dataframe.svg\",width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6429f8e",
   "metadata": {},
   "source": [
    "### Reading the data - National Food Survey UK \n",
    "\n",
    "The National Food Survey (NFS), which closed in 2000, was the longest-running continuous survey of household food consumption and expenditure in the world. It was originally set up in 1940 by the then Ministry of Food to monitor the adequacy of the diet of urban 'working class' households in wartime, but it was extended in 1950 to become representative of households throughout Great Britain (the UKDA holds NFS data from 1974-2000 only). \n",
    "- Information: https://www.gov.uk/government/statistics/family-food-open-data\n",
    "- Source: https://uofi.box.com/s/v3pchnfl20i8qw3qwur42eji9f851aak\n",
    "We have a file that contains all the .csv files that we'll read. __FIRST__: Download that data and put it somewhere you know where it is! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f268cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pwd #check current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aad859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd \"C:\\Users\\Hanna Willwerth\\Box\\nfs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce3cca9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pwd #check current directory to ensure it changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3d5d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9affbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('NFS_2000.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4634ba",
   "metadata": {},
   "source": [
    " ### Some variables from the dataset\n",
    " - hhno : household id\n",
    " - styr : year column\n",
    " - minfd : identifier of food category\n",
    " - cq: consumption\n",
    " - memhh : number of members of the household"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa60aac",
   "metadata": {},
   "source": [
    "As usual, we can do pandas operations... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a58362",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('minfd').minfd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccc4ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('minfd').cq.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b08277",
   "metadata": {},
   "source": [
    "## What can we do with Dask ?\n",
    "\n",
    "Most of the functions are part of pandas dataframe API: https://docs.dask.org/en/latest/dataframe-api.html\n",
    "\n",
    "Some examples of parallelizable operations (fast):\n",
    "\n",
    "- Elementwise operations: `df.x + df.y, df * df`\n",
    "- Row-wise selections: `df[df.x > 0]`\n",
    "- Loc: `df.loc[4.0:10.5]`\n",
    "- Common aggregations: `df.x.max(), df.max()`\n",
    "- Is in: `df[df.x.isin([1, 2, 3])]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79294c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, progress\n",
    "client = Client(n_workers=2, threads_per_worker=2, memory_limit='1GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cbe013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3faa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that we are reading ALL csv files. \n",
    "df = dd.read_csv(\"NFS*.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda3059e",
   "metadata": {},
   "source": [
    "Notice that:\n",
    "- Nothing yet is loaded in to memory\n",
    "- Meta-information from pandas is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64117bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bc890c",
   "metadata": {},
   "source": [
    "Notice that ```npartitions=27``` is the number of csv files (and years in this case) that we have for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63248f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame.head is one operation that is not lazy\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2528d521",
   "metadata": {},
   "source": [
    "- styr : year column\n",
    "- minfd : identifier of food category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7263a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cq.mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97672e48",
   "metadata": {},
   "source": [
    "What is up with this?? Nothing happened? We need to add the ```.compute()``` to the end of the code to actually execute the action using Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f63876",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cq.mean().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7438b04",
   "metadata": {},
   "source": [
    "### What did we just do??\n",
    "We calculated the average of a column acros 27 large CSV files wihtout having to read them all into memory and concatenate them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19bfb6d",
   "metadata": {},
   "source": [
    "###  Partitions\n",
    "\n",
    "- By default the data is partitioned by each file\n",
    "- In our case, this is good. The files have a natural partition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c0996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.npartitions\n",
    "# Number of. CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d109b2e8",
   "metadata": {},
   "source": [
    "#### Each partition is just a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fb6d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.partitions[5].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b89b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.partitions[5].compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d242c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.known_divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec76c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('styr', sorted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f627b5a",
   "metadata": {},
   "source": [
    "We know that each CSV is divided up by year, but Dask does not know that and will not unless we tell it explicitly. So that is what we do when we `df.set_index('styr',sorted=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e0dfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.known_divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afef66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97bd9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3526c8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.divisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bfe8fb",
   "metadata": {},
   "source": [
    "## Fast access to subsets of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaee9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceec590f",
   "metadata": {},
   "source": [
    "However, this IS a lazy operation. So, we need to add `compute()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa33ab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[2000].compute() #here we are selecting the index '2000' \n",
    "#which is the year 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f55106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df) #This is how big the whole data set is. Over 833,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e36b3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('minfd').minfd.count().nlargest(10).compute() \n",
    "# Remember 'minfd' is the food category \n",
    "#aggregation API is fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dffa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "minfd = 401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b74727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "food_mapping = pd.read_csv(\"food_mapping.csv\", index_col='minfd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebf968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb68727a",
   "metadata": {},
   "source": [
    "#### What was the most consumed food group in 1974? \n",
    "#### What was the most consumed food group overall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838b90a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1974 = df.loc[1974]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac40e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_74 = df_1974.minfd.value_counts().nlargest(10).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba5195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da91c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_74df=top_74.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0df911",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#These are the top consumed Food categories in 1974\n",
    "top_74df_merged=top_74df.merge(food_mapping, how='left', right_index=True, left_index=True)\\\n",
    ".sort_values(by='minfd', ascending=False)\n",
    "top_74df_merged\n",
    "#This is great but it feels like a lot of uneeded info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87468cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_74df_merged[['minfd', 'fd gp description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3af30d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = df.minfd.value_counts().nlargest(10).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a70437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a32fcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "topdf=top.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c71ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the top consumed Food categories in 1974\n",
    "topdf_merged=topdf.merge(food_mapping, how='left', right_index=True, left_index=True)\\\n",
    ".sort_values(by='minfd', ascending=False)\n",
    "topdf_merged[['minfd', 'fd gp description']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80b15fc",
   "metadata": {},
   "source": [
    "### map_partitions\n",
    "- If we have a code that works well on a single data frame and we want to apply an \"embarransingly parallel way\" across many pandas data frames that live inside the `dask` data frame. \n",
    "- Map partitions does what you might expect\n",
    "- Maps a function across partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b04a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.map_partitions(len).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ec3b97",
   "metadata": {},
   "source": [
    "### Let's calculate the most frequently purchase food group for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c81d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent_food(partition):\n",
    "    # partition is a pandas.DataFrame\n",
    "    minfd = partition.minfd.value_counts().nlargest(1).index[0]\n",
    "    description = food_mapping.loc[minfd].minfddesc.iloc[0]\n",
    "    year = int(partition.index[0])\n",
    "    return pd.DataFrame({'year': [year], 'description': [description]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca03612",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnfd_year = df.map_partitions(most_frequent_food, \n",
    "                              meta={'year': int,\n",
    "                                    'description': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4530bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnfd_year.compute()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
